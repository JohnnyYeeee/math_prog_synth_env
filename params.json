{
    "num_problems_per_module": 1000000,
    "validation_percentage": 0.2,
    "encode_question": true,
    "max_sequence_length": 125,
    "question_vocab_size": 250,
    "max_difficulty": 0,
    "univariate_differentiation": true,
    "num_environments": 50,
    "tokenizer_filepath": "environment/tokenization/tokenizer.model",
    "max_formal_elements": 13,
    "max_num_nodes": 7,
    "all_data_dirpath": "mathematics_dataset-v1.0/train-easy",
    "data_dirpath": "mathematics_dataset-v1.0/train",
    "test_data_dirpath": "mathematics_dataset-v1.0/test",


}


num_problems_per_module : 10 ** 6
validation_percentage : 0.2
encode_question : True
max_sequence_length : 125
question_vocab_size : 250
max_difficulty : 0
univariate_differentiation : True
num_environments = 50
tokenizer_filepath = "environment/tokenization/tokenizer.model"
max_formal_elements = 13
max_num_nodes = 7

all_data_dirpath = "mathematics_dataset-v1.0/train-easy"
test_percentage = 0.1
# Train and test paths
data_dirpath = "mathematics_dataset-v1.0/train"
test_data_dirpath = "mathematics_dataset-v1.0/test"
selected_filenames = [
                          'numbers__is_factor.txt',
                          'numbers__is_prime.txt',
                          'numbers__list_prime_factors.txt',
                          'calculus__differentiate.txt',
                          'polynomials__evaluate.txt',
                          'numbers__div_remainder.txt',
                          'numbers__gcd.txt',
                          'numbers__lcm.txt',
                          'algebra__linear_1d.txt',
                          'algebra__polynomial_roots.txt',
                          'algebra__linear_2d.txt',
;                          'algebra__linear_1d_composed.txt',
;                          'algebra__linear_2d_composed.txt',
;                          'algebra__polynomial_roots_composed.txt',
;                          'calculus__differentiate_composed.txt',
;                          'numbers__div_remainder_composed.txt',
;                          'numbers__gcd_composed.txt',
;                          'numbers__is_factor_composed.txt',
;                          'numbers__is_prime_composed.txt',
;                          'numbers__lcm_composed.txt',
;                          'numbers__list_prime_factors_composed.txt',
;                          'polynomials__evaluate_composed.txt',
;                          'polynomials__compose.txt'
                     ]

# used only to initialize the tokenizer
types = [
        "EquationOrExpression",
        "Equation",
        "Function",
        "Expression",
        "Variable",
        "Value",
        "Rational"
        ]

operators = [
            "lookup_value",
            "solve_system",
            "append",
            "append_to_empty_list",
            "factor",
            "differentiate",
            "mod",
            "gcd",
            "divides",
            "is_prime",
            "lcm",
            "lcd",
            "prime_factors",
            "evaluate_function",
            "not_op"
;            "differentiate_wrt",
;            "make_equation",
;            "simplify",
;            "make_function",
;            "replace_arg",
;            "lookup_value_equation",
;            "extract_isolated_variable",
;            "substitution_left_to_right",
            ]
